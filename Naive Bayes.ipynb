{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><b>Notes</b>\n",
    "        <ul>\n",
    "            <li> Formula:</li>$P(A | B) = \\frac{P(B | A) * P(A)}{P(B)}$\n",
    "            <li>The denominator gets removed because no longer strict the result on the probability (the value \n",
    "                stills summarize as we pick the class with higher probability)</li>\n",
    "            <li>Calculating the probability or likelihood of observing a given real value given x<sub>1</sub> \n",
    "                is diffucult. One way to do this is to assume that x<sub>1</sub> values are drawn from a \n",
    "                distribbution such as Gaussian distribution.</li>\n",
    "            <li>Use  of a probability framework for fiting a model to a training data (maximum a posteriory MAP).\n",
    "            </li>\n",
    "            <li>It is known to produce biased estimates, however, if goal is to rank records according to the \n",
    "                proability that y=1, unbiased estimates of probability are not needed and naive bayes produces a \n",
    "                good result</li>\n",
    "            <li>when a predictor category is absent in the training data the model assigns zero probability to \n",
    "                the outcome variable in the new data (most implementations use a smoothing parameter - laplace \n",
    "                smoothing to prevent this.</li>\n",
    "            <li>\n",
    "        </ul>\n",
    "    <li><b>Assumptions</b></li>\n",
    "    <ul>\n",
    "        <li>Features are conditionally independent given the class</li>\n",
    "        <li>Relationship between the features and the class label remains constant</li>\n",
    "        <li>Irrelevant features can't affect the classification decision</li>\n",
    "        <li>Need sufficient amount of data</li>\n",
    "    </ul>  \n",
    "    <li><b>Steps</b>\n",
    "        <ol>\n",
    "            <li>Separate by class</li>\n",
    "            <li>Summarize data set (for each class): calculate mean, standard deviation, and number of \n",
    "                observations for each feature (columns)</li>\n",
    "            <li>Implement Gaussian Probability Density Function: use X, mean and std to calculate f(x) and get \n",
    "                the training data probabilities</li>\n",
    "            <li>Calculate the probabilities for new data (probabilities are calculated separetely for each \n",
    "                class</li>\n",
    "        </ol>\n",
    "    <li><b>Sources:</b></li>\n",
    "    <ul>\n",
    "        <li><a href=\"https://machinelearningmastery.com/bayes-theorem-for-machine-learning/\">Machine Learning \n",
    "            Mastery</a></li>\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Bayes Theorem</b>\n",
    "<ul>\n",
    "    <li>Assumes each input variable is independent upon all other variables, if we remove this approach to make   \n",
    "        things less complex, and assume each input variable as bbeing independent from each other then the \n",
    "        dependent conditional probability becomes independent conditonal probaility.</li>\n",
    "    <li><b>Bayes optimal classifier:</b> get variants through a hypothesis space and works by building a \n",
    "        proabilistic model of the objective function</li>\n",
    "    <li>Marginal probability: the probability of an event irrespective of the outcomes or another random \n",
    "        variables e.g P(A)</li>\n",
    "    <li>Joint probability: probability of two or more simultaneous events e.g. P(A and B) or P(A,B) where P(A,B) \n",
    "        = P(A|B) * P(B)</li>\n",
    "    <li>Conditional probability: probability to one or more event given the occurance of another event e.g. P(A \n",
    "        given B) or P(A|B)</li>\n",
    "    <li>When P(B) is not available P(B) = P(B|A)*P(A) + P(B|not A)*P(not A)</li>\n",
    "    <li>Complements</li>\n",
    "    <ul>\n",
    "        <li>P(not A) = 1 - P(A)</li>\n",
    "        <li>P(B|not A) = 1 - P(not B|not A)</li>\n",
    "        <li>P(not B| not A) = P(B|not A)</li>\n",
    "    </ul>\n",
    "    <li>Other definition</li>\n",
    "    <ul>\n",
    "        <li>P(A|B) -> posterior probability</li>\n",
    "        <li>P(A) -> prior probability </li>\n",
    "        <li>P(B|A) -> likelihood</li>\n",
    "        <li>P(B) -> evidence</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
